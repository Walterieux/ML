{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from implementations import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250000,), (250000, 30))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tX.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (implementations.py, line 15)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\jeang\\.julia\\conda\\3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3331\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-b98ad6691567>\"\u001b[1;36m, line \u001b[1;32m2\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from implementations import *\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\jeang\\ML\\scripts\\implementations.py\"\u001b[1;36m, line \u001b[1;32m15\u001b[0m\n\u001b[1;33m    def compute_loss(y, tx, w):\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n",
      "(250000, 24)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'least_square' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-3bf1504f4ef7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Start gradient descent.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mgradient_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleast_square\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtX1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'least_square' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"taken from ex02:\"\"\"\n",
    "# from gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 1000\n",
    "gamma = 1e-9\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "#A=tX[0:30]\n",
    "#b=y[0:30]\n",
    "#w_initial=np.linalg.lstsq(A,b,rcond=None)[0]\n",
    "print(np.shape(tX))\n",
    "\n",
    "b=variance_half_max_index(tX)\n",
    "tX1=tX[:,b]\n",
    "print(np.shape(tX1))\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gradient_w, gradient_loss = least_square(y, tX1)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"Gradient Descent: execution time={t:.3f} seconds\".format(t=exection_time))\n",
    "print(\"gradient loss = \", gradient_loss, \"\\n W = \",gradient_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Least squares (using normal equations) test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least squares: execution time=0.440 seconds\n",
      "Loss =  0.3396868094770345 \n",
      " W =  [ 8.03494350e-05 -7.20202266e-03 -6.05417273e-03 -5.47559077e-04\n",
      " -1.93874687e-02  4.73451613e-04 -2.60379057e-02  3.25106299e-01\n",
      " -3.80780015e-05 -2.72785402e+00 -2.21220141e-01  9.50794097e-02\n",
      "  6.40351607e-02  2.73611370e+00 -3.31801097e-04 -9.54325136e-04\n",
      "  2.74087044e+00 -5.34165258e-04  9.73498900e-04  3.69225050e-03\n",
      "  3.54487183e-04 -5.43344617e-04 -3.30448035e-01 -1.40800497e-03\n",
      "  8.31432840e-04  1.02117276e-03 -1.68047418e-03 -5.83664795e-03\n",
      " -1.11088002e-02  2.72831395e+00]\n"
     ]
    }
   ],
   "source": [
    "# Start.\n",
    "start_time = datetime.datetime.now()\n",
    "weights, loss = least_squares(y, tX)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"Least squares: execution time={t:.3f} seconds\".format(t=exection_time))\n",
    "print(\"Loss = \", loss, \"\\n W = \", weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression (using normal equations) test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least squares: execution time=0.466 seconds\n",
      "Loss =  0.3516066841491274 \n",
      " W =  [ 2.48519324e-04 -8.96465390e-03 -2.24753247e-03 -2.19688733e-03\n",
      " -8.28785858e-04  5.27482033e-04 -1.23580011e-02  2.78401608e-02\n",
      "  6.37660259e-05  3.17281194e-03 -2.55552723e-02  4.56064526e-02\n",
      "  1.07748012e-02  6.17277403e-03 -3.38880835e-04 -1.20732147e-03\n",
      "  2.51582382e-03 -4.25916162e-04  8.32986709e-04  4.90332267e-03\n",
      "  4.17025377e-04 -7.70891369e-04 -2.48302577e-02  1.45686817e-03\n",
      " -7.63838506e-04 -5.43201301e-04  2.59945303e-04  1.61198112e-03\n",
      "  1.83180262e-04 -5.51499664e-03]\n"
     ]
    }
   ],
   "source": [
    "lambda_ = 0.5\n",
    "\n",
    "# Start.\n",
    "start_time = datetime.datetime.now()\n",
    "weights, loss = ridge_regression(y, tX, lambda_)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"Least squares: execution time={t:.3f} seconds\".format(t=exection_time))\n",
    "print(\"Loss = \", loss, \"\\n W = \", weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0.000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test1, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeang\\ML\\scripts\\implementations.py:283: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation = covariance / outer_v\n",
      "C:\\Users\\jeang\\ML\\scripts\\implementations.py:285: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  return np.where(correlation >= 0.9, 1, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test : (25000, 225)\n",
      "Test: Loss =  0.2866465236092669\n",
      "[-1.33562716e-01  2.13604493e-03 -1.51257342e-05  5.53552258e-08\n",
      " -1.12039054e-10  1.26122769e-13 -7.37030327e-17  1.73784095e-20\n",
      "  1.62960583e-02 -7.24456525e-04  8.51513763e-06 -4.46587480e-08\n",
      "  1.20487415e-10 -1.70819246e-13  1.17714046e-16 -2.95162734e-20\n",
      "  1.32327544e-02 -2.97953103e-04  1.80702205e-06 -5.22770168e-09\n",
      "  8.14332079e-12 -6.97613106e-15  3.08787423e-18 -5.51046857e-22\n",
      " -5.15354341e-03  1.50304419e-04 -1.68949700e-06  1.04938535e-08\n",
      " -3.60186943e-11  6.73364030e-14 -6.39482887e-17  2.40727458e-20\n",
      " -5.02595963e-02 -7.28839783e-02 -2.14016670e-02  6.71759345e-02\n",
      " -2.90056553e-02  5.25600643e-03 -4.35596512e-04  1.35236369e-05\n",
      " -5.08174290e-03  1.27089651e-05 -1.66486322e-08  1.24655975e-11\n",
      " -5.50874573e-15  1.41048702e-18 -1.92263816e-22  1.07362424e-26\n",
      " -5.65337396e-02 -2.60545423e-03  6.84500686e-05  2.93944056e-05\n",
      "  1.66214414e-06 -2.08052842e-07 -6.02166311e-09  4.56633248e-10\n",
      "  2.39477720e-01  2.47077089e-01  5.30931905e-02 -1.02619433e-01\n",
      "  1.85831216e-02  4.33657392e-03 -1.49395398e-03  1.10348026e-04\n",
      "  2.37147209e-03 -1.45169328e-04  2.26611915e-06 -1.29725366e-08\n",
      "  3.13370188e-11 -2.72111912e-14 -1.81294930e-18  6.21421238e-21\n",
      " -7.93668403e-03  7.95670344e-05 -3.76633374e-07  8.91637977e-10\n",
      " -1.15320390e-12  8.26874458e-16 -3.07784897e-19  4.62769949e-23\n",
      " -8.95983515e-02 -6.82062998e-02  7.38385135e-02 -2.34795036e-02\n",
      "  3.49680160e-03 -2.67216484e-04  1.01113167e-05 -1.49847423e-07\n",
      " -5.87118431e-02  7.36045269e-02  7.16882328e-02  3.17223168e-02\n",
      "  6.17686625e-02 -5.22586227e-02 -3.54861658e-02  9.92446955e-03\n",
      "  7.61094777e-02  1.11520320e-01  8.44421941e-02  5.03949192e-02\n",
      "  2.16082145e-02 -3.70230687e-04 -1.64862769e-02 -2.80350239e-02\n",
      "  4.50054210e-02 -4.79091689e-04  2.00072401e-06  3.66493051e-10\n",
      " -2.75717883e-11  8.27896601e-14 -9.85010164e-17  4.21403037e-20\n",
      "  4.89845012e-03  2.45176957e-02 -1.21548563e-02 -3.34928833e-02\n",
      "  5.03739200e-03  8.29132803e-03 -5.53879861e-04 -6.66024578e-04\n",
      " -3.23932474e-03 -3.33215679e-03  6.69770078e-04  6.17507276e-04\n",
      "  2.36070045e-05 -9.75227416e-05 -5.77844041e-06  7.08652769e-06\n",
      "  6.31831357e-02 -1.53310798e-03  1.99937095e-05 -1.43684286e-07\n",
      "  5.87111795e-10 -1.35047814e-12  1.61831338e-15 -7.80595369e-19\n",
      "  2.02447940e-03 -2.04795362e-02 -3.01623426e-03 -1.14931817e-02\n",
      "  1.22742382e-03  2.97253685e-03 -1.43986509e-04 -2.23911114e-04\n",
      "  6.91707957e-04 -1.02446185e-04 -9.96099819e-04  1.99757149e-04\n",
      "  3.97705908e-04 -8.52244987e-05 -3.49485275e-05  6.27927986e-06\n",
      " -9.58538819e-03  1.96061296e-04 -1.82424360e-06  7.76148895e-09\n",
      " -1.30558206e-11 -1.86028932e-15  2.76414165e-17 -2.06256866e-20\n",
      "  2.87015480e-03 -5.95518888e-03 -2.33956857e-03  2.02064607e-03\n",
      "  5.36503790e-04 -2.08475049e-04 -3.59176580e-05  5.02563983e-06\n",
      "  1.11500269e-02  1.03837007e-02  8.96711231e-03  6.36363660e-03\n",
      "  2.27024791e-03 -3.86726531e-03 -7.84034325e-03  2.76754157e-03\n",
      "  1.30379841e-02 -1.35093018e-04  8.41215634e-07 -3.06573834e-09\n",
      "  6.45935512e-12 -7.54417529e-15  4.37808053e-18 -9.23518899e-22\n",
      " -1.64111205e-03  4.11834141e-02 -1.30779622e-03  2.87676872e-03\n",
      "  2.74978015e-04 -4.09859666e-04 -1.05244364e-05  1.22883420e-05\n",
      " -3.32855369e-03  5.71450981e-04  1.25655310e-03  3.30343899e-05\n",
      " -2.69979152e-04  1.81486150e-05  2.20505933e-05 -3.84692289e-06\n",
      " -6.91530790e-03  3.71274422e-04 -4.72014421e-06  2.85303135e-08\n",
      " -9.29417925e-11  1.66141410e-13 -1.52874758e-16  5.65144858e-20\n",
      "  3.10018709e-03  5.39091378e-02 -1.67267878e-03 -1.55870514e-03\n",
      "  2.07352549e-04  1.29528099e-05 -6.65367281e-06  5.18258969e-07\n",
      "  2.73283019e-03 -1.95836365e-02 -4.91227197e-03  6.44165127e-03\n",
      "  1.15730212e-03 -8.54199247e-04 -6.95636228e-05  3.98060187e-05\n",
      " -4.99622653e-02]\n",
      "Test: Real  accuracy =  0.80384\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tX,tX_test=replace_999_data_elem(tX,tX_test)\n",
    "lambda_ = 0.001\n",
    "\n",
    "\n",
    "#tX_1,tX_test=replace_999_data_elem(tX,tX_test1)\n",
    "tX_1=replace_999_data_elem(tX)\n",
    "\n",
    "\n",
    "features=get_uncorellated_features(tX_1)\n",
    "tX_test=replace_999_data_elem(tX_test1)\n",
    "#### on prend que les features importants pas ceux qui sont correlés à plus de 90% avec les autres\n",
    "#tX_1=tX_1[:,features]\n",
    "\n",
    "#tX_test=tX_test1[:,features]\n",
    "#index_variance=sorted_by_variance(tX)\n",
    "#tX=tX[:,index_variance]\n",
    "#tX_test=tX_test[:,index_variance]\n",
    "#print ('Covariance matrix:\\n', ACov)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "fig.set_size_inches(10, 10)\n",
    "\n",
    "ax0 = plt.subplot(2, 2, 1)\n",
    "plt.title(\"Correlation matrix of different features\")\n",
    "# Choosing the colors\n",
    "cmap = sns.color_palette(\"GnBu\", 10)\n",
    "sns.heatmap(calculateCovariance(replace_999_data_elem(tX),0), cmap=cmap, vmin=0)\n",
    "#plt.imshow(calculateCovariance(tX,1), cmap='Greys',  interpolation='nearest')\n",
    "\n",
    "ax1 = plt.subplot(2, 2, 2)\n",
    "plt.title(\"Correlation matrix with black box when values exceed 90%\")\n",
    "# data can include the colors\n",
    "plt.imshow(calculateCovariance(replace_999_data_elem(tX),True), cmap='Greys',  interpolation='nearest')\n",
    "\n",
    "# Remove the top and right axes from the data plot\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "\n",
    "#creation of segmentation train and train_test 90% / 10%\n",
    "#y_train,y_train_test,tx_train,tx_train_test=data_train_test(y,tX_1,0.90)\n",
    "y_train,y_train_test,tx_train,tx_train_test=data_train_test(y,tX,0.90)\n",
    "\n",
    "#calculate of the weights with the train part \n",
    "#tx_train_poly=build_poly(tx_train,5)\n",
    "tX_train_poly=build_poly_variance(tx_train,0,8,8,8,8,8)\n",
    "\n",
    "features_poly=get_uncorellated_features(tX_train_poly)\n",
    "#print(\"shape tX_train_poly :\",np.shape(tX_train_poly))\n",
    "#tX_train_poly=tX_train_poly[:,features_poly]\n",
    "#print(\"shape tX_train_poly after :\",np.shape(tX_train_poly))\n",
    "\n",
    "\n",
    "weights, loss = ridge_regression(y_train, tX_train_poly, lambda_)\n",
    "#tX_train_test_poly=build_poly(tx_train_test,5)\n",
    "tX_train_test_poly=build_poly_variance(tx_train_test,0,8,8,8,8,8)\n",
    "#tX_train_test_poly=tX_train_test_poly[:,features_poly]\n",
    "print(\"train test :\", np.shape(tX_train_test_poly))\n",
    "print(\"Test: Loss = \", compute_loss(y_train_test, tX_train_test_poly, weights))\n",
    "print(\"Test: Real  accuracy = \", compute_loss_binary(y_train_test,tX_train_test_poly,weights))\n",
    "\n",
    "\n",
    "#tX_test_poly = build_poly_variance(tX_test,0,8,8,8,8,8)\n",
    "#0.28631\n",
    "#0.2853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/result.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test_poly)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,best_array=test_find_degree(y_train,y_train_test,tx_train,tx_train_test)\n",
    "print(\"Loss = \", loss, \"\\n best_array = \", best_array)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n",
      "y shape (250000,)\n",
      "tX shape (250000, 30)\n",
      "(array([0], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "features=get_uncorellated_features(tX)\n",
    "#print(features)\n",
    "#print(len(features[0]))\n",
    "print(features)\n",
    "print(len(features))\n",
    "print(\"y shape\", np.shape(y))\n",
    "print(\"tX shape\", np.shape(tX))\n",
    "print(calculateCovariance_y_tX(tX,y))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 22 24 25\n",
      " 26 27 28]\n",
      "225000\n",
      "shape de transpose tx :  (55, 225000)  and shape of sigma(np.dot(tx,w))  (225000,)\n",
      "n_iter :  4999\n",
      "loss 118455.7685816562\n",
      "[ 8.63301501e-03  5.74407927e-03 -1.68379130e-04 -1.84667783e-02\n",
      "  4.72807847e-03 -3.46162055e-02  3.80634196e-04 -1.21109740e-02\n",
      " -5.37447797e-05 -2.08409343e-04 -4.90271373e-03  4.65912460e-04\n",
      "  7.97351493e-05  1.93080764e-04  2.02383858e-04  6.28502990e-04\n",
      " -4.67779941e-04 -2.82359169e-04  4.84347809e-03 -9.17441032e-04\n",
      "  1.37357929e-05 -1.15632846e-04  4.80910283e-05  1.22570008e-04\n",
      "  1.94303429e-06  4.67688104e-06  2.31248984e-03  7.15707987e-02\n",
      " -2.61439880e-06 -5.45614342e-05 -6.85730153e-06  1.33352080e-04\n",
      "  1.80398325e-03  4.65126867e-02 -1.95767448e-06 -7.58445598e-05\n",
      "  8.31223658e-06  1.31517913e-04  4.36813388e-04  2.26901630e-02\n",
      "  2.25225091e-06  1.30896229e-04  2.06903120e-05 -1.05806476e-05\n",
      "  1.50081339e-06  3.19275121e-04 -4.26374477e-07  1.03722759e-04\n",
      "  7.41041679e-05 -1.16497807e-02  1.39556298e-06 -5.07815005e-05\n",
      " -1.62672451e-06 -6.42794895e-06  4.20902344e-05]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (25000,76) and (55,) not aligned: 76 (dim 1) != 55 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-1eeb5185f9d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogistic_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtX_train_poly\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"real loss: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcompute_loss_binary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtX_train_test_poly\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;31m#print(\"train test :\", np.shape(tX_train_test_poly))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m#print(\"Test: Loss = \", compute_loss(y_train_test, tX_train_test_poly, weights))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ML\\scripts\\implementations.py\u001b[0m in \u001b[0;36mcompute_loss_binary\u001b[1;34m(y_test, tx_test, w_train)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mpredicted_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mpredicted_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_y\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0msum_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredicted_y\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (25000,76) and (55,) not aligned: 76 (dim 1) != 55 (dim 0)"
     ]
    }
   ],
   "source": [
    "lambda_=0.0\n",
    "tX_1=replace_999_data_elem(tX)\n",
    "features=get_uncorellated_features(tX_1)\n",
    "tX_test=replace_999_data_elem(tX_test1)\n",
    "print(features)\n",
    "#### on prend que les features importants pas ceux qui sont correlés à plus de 90% avec les autres\n",
    "tX_1=tX_1[:,features]\n",
    "\n",
    "tX_test=tX_test1[:,features]\n",
    "y_train,y_train_test,tx_train,tx_train_test=data_train_test(y,tX_1,0.90)\n",
    "\n",
    "#calculate of the weights with the train part \n",
    "#tx_train_poly=build_poly(tx_train,5)\n",
    "tX_train_poly=build_poly_variance(tx_train,0,2,2,2,2,2)\n",
    "weights, loss = ridge_regression(y_train, tX_train_poly, lambda_)\n",
    "#tX_train_test_poly=build_poly(tx_train_test,5)\n",
    "tX_train_test_poly=build_poly_variance(tx_train_test,0,2,2,2,2)\n",
    "#Define initial values \n",
    "initial_w=np.zeros(np.shape(tX_train_poly)[1])\n",
    "#on change ici parce qu'on applique comme dans le cours avec des 0 ou des -1.\n",
    "y_train=np.where(y_train==-1,0,1)\n",
    "max_iters=5000\n",
    "gamma=1e-9\n",
    "weights,loss=logistic_regression(y_train, tX_train_poly, initial_w, max_iters, gamma)\n",
    "print(\"loss\",loss)\n",
    "print(\"real loss: \",compute_loss_binary(y_train_test,tX_train_test_poly,weights))\n",
    "#print(\"train test :\", np.shape(tX_train_test_poly))\n",
    "#print(\"Test: Loss = \", compute_loss(y_train_test, tX_train_test_poly, weiughts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_train_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-21c4cce852b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_fct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ML\\scripts\\implementations.py\u001b[0m in \u001b[0;36mtest_fct\u001b[1;34m(tX, y, lambda_, i)\u001b[0m\n\u001b[0;32m    332\u001b[0m     \u001b[0mtX_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtX_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;31m#creation of segmentation train and train_test 90% / 10%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m     \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtx_train_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_train_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtX_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m     \u001b[1;31m#calculate of the weights with the train part\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;31m#tx_train_poly=build_poly(tx_train,5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_train_test' is not defined"
     ]
    }
   ],
   "source": [
    "lambdas=np.zeros(20)\n",
    "results=np.zeros((10,20))\n",
    "lambdas[1]=1e-6\n",
    "for i in range(2,20):\n",
    "    lambdas[i]=lambdas[i-1]*10\n",
    "for j in range(11):\n",
    "    for i in range(20):\n",
    "        results[j,i]=test_fct(tX,y,lambdas[i],j)\n",
    "\n",
    "plt.imshow(results)\n",
    "print(\"our maximum accuracy is : \" ,np.max(results))\n",
    "indexs=zip(*np.where(results == np.max(results)))\n",
    "print(\"The value of lambdas = \", lambdas[indexs[1]], \" and the value of j :\" , indexs[0])\n",
    "#plt.plot(lambdas,results)\n",
    "#plt.scatter(lambdas,results)\n",
    "#plt.xscale(\"log\")\n",
    "#plt.xlabel(\"lambdas\")\n",
    "#plt.ylabel(\"accuracy\")\n",
    "#plt.title(\"lambdas value and accuracy\")\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
