{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from implementations import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((250000,), (250000, 30))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tX.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n",
      "(250000, 24)\n",
      "Gradient Descent: execution time=0.048 seconds\n",
      "gradient loss =  0.3559770984135593 \n",
      " W =  [ 2.26971848e-04  6.56522489e-04 -2.07872311e-03  2.66859544e+00\n",
      "  3.25911884e-04  2.67330024e+00  5.00287345e-03 -9.31223839e-03\n",
      " -1.75704625e-03 -2.00046630e-03  2.66082659e+00 -2.66378165e+00\n",
      " -6.79222194e-04  2.79992082e-04 -3.52941170e-02 -6.10160688e-03\n",
      " -1.00960843e-02  1.08584292e-01 -5.86224270e-02  1.14536818e-03\n",
      " -4.51466862e-04 -1.26157626e-03  1.86677641e-03  5.58306206e-04]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"taken from ex02:\"\"\"\n",
    "# from gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 1000\n",
    "gamma = 1e-9\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "#A=tX[0:30]\n",
    "#b=y[0:30]\n",
    "#w_initial=np.linalg.lstsq(A,b,rcond=None)[0]\n",
    "print(np.shape(tX))\n",
    "\n",
    "b=variance_half_max_index(tX)\n",
    "tX1=tX[:,b]\n",
    "print(np.shape(tX1))\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gradient_w, gradient_loss = least_squares(y, tX1)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"Gradient Descent: execution time={t:.3f} seconds\".format(t=exection_time))\n",
    "print(\"gradient loss = \", gradient_loss, \"\\n W = \",gradient_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares (using normal equations) test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least squares: execution time=0.339 seconds\n",
      "Loss =  0.3396868094770345 \n",
      " W =  [ 8.03494350e-05 -7.20202266e-03 -6.05417273e-03 -5.47559077e-04\n",
      " -1.93874687e-02  4.73451613e-04 -2.60379057e-02  3.25106299e-01\n",
      " -3.80780015e-05 -2.72785402e+00 -2.21220141e-01  9.50794097e-02\n",
      "  6.40351607e-02  2.73611370e+00 -3.31801097e-04 -9.54325136e-04\n",
      "  2.74087044e+00 -5.34165258e-04  9.73498900e-04  3.69225050e-03\n",
      "  3.54487183e-04 -5.43344617e-04 -3.30448035e-01 -1.40800497e-03\n",
      "  8.31432840e-04  1.02117276e-03 -1.68047418e-03 -5.83664795e-03\n",
      " -1.11088002e-02  2.72831395e+00]\n"
     ]
    }
   ],
   "source": [
    "# Start.\n",
    "start_time = datetime.datetime.now()\n",
    "weights, loss = least_squares(y, tX)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"Least squares: execution time={t:.3f} seconds\".format(t=exection_time))\n",
    "print(\"Loss = \", loss, \"\\n W = \", weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression (using normal equations) test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least squares: execution time=0.365 seconds\n",
      "Loss =  0.3516066841491274 \n",
      " W =  [ 2.48519324e-04 -8.96465390e-03 -2.24753247e-03 -2.19688733e-03\n",
      " -8.28785858e-04  5.27482033e-04 -1.23580011e-02  2.78401608e-02\n",
      "  6.37660259e-05  3.17281194e-03 -2.55552723e-02  4.56064526e-02\n",
      "  1.07748012e-02  6.17277403e-03 -3.38880835e-04 -1.20732147e-03\n",
      "  2.51582382e-03 -4.25916162e-04  8.32986709e-04  4.90332267e-03\n",
      "  4.17025377e-04 -7.70891369e-04 -2.48302577e-02  1.45686817e-03\n",
      " -7.63838506e-04 -5.43201301e-04  2.59945303e-04  1.61198112e-03\n",
      "  1.83180262e-04 -5.51499664e-03]\n"
     ]
    }
   ],
   "source": [
    "lambda_ = 0.5\n",
    "\n",
    "# Start.\n",
    "start_time = datetime.datetime.now()\n",
    "weights, loss = ridge_regression(y, tX, lambda_)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"Least squares: execution time={t:.3f} seconds\".format(t=exection_time))\n",
    "print(\"Loss = \", loss, \"\\n W = \", weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = 0.000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape de transpose tx :  (30, 225000)  and shape of sigma(np.dot(tx,w))  (225000, 1)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "n_iter :  199\n",
      "Logistic Regression: execution time=4.456 seconds\n",
      "Accuracy =  -8876.01208 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Start\n",
    "start_time = datetime.datetime.now()\n",
    "y_train,y_train_test,tx_train,tx_train_test = split_data_train_test(y,tX,0.90)\n",
    "weights, loss = logistic_regression( np.transpose(np.matrix(y_train)), standardize(tx_train), np.zeros((tX.shape[1],1)), 200, 1e-9)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"Logistic Regression: execution time={t:.3f} seconds\".format(t=exection_time))\n",
    "print(\"Accuracy = \", compute_loss_binary(y_train_test,tx_train_test,weights), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test1, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/Desktop/MachineLearning/ML/scripts/implementations.py:342: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation = covariance / outer_v\n",
      "/home/david/Desktop/MachineLearning/ML/scripts/implementations.py:344: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  return np.where(correlation >= 0.9, 1, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test : (25000, 225)\n",
      "Test: Loss =  0.286680118885784\n",
      "Test: Real  accuracy =  0.73156\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tX,tX_test=replace_999_data_elem(tX,tX_test)\n",
    "lambda_ = 0.001\n",
    "\n",
    "\n",
    "#tX_1,tX_test=replace_999_data_elem(tX,tX_test1)\n",
    "tX_1=replace_999_data_elem(tX)\n",
    "\n",
    "\n",
    "features=get_uncorrelated_features(tX_1)\n",
    "tX_test=replace_999_data_elem(tX_test1)\n",
    "#### on prend que les features importants pas ceux qui sont correlés à plus de 90% avec les autres\n",
    "tX_1=tX_1[:,features]\n",
    "\n",
    "tX_test=tX_test1[:,features]\n",
    "#index_variance=sorted_by_variance(tX)\n",
    "#tX=tX[:,index_variance]\n",
    "#tX_test=tX_test[:,index_variance]\n",
    "#print ('Covariance matrix:\\n', ACov)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "fig.set_size_inches(10, 10)\n",
    "\n",
    "ax0 = plt.subplot(2, 2, 1)\n",
    "plt.title(\"Correlation matrix of different features\")\n",
    "# Choosing the colors\n",
    "cmap = sns.color_palette(\"GnBu\", 10)\n",
    "sns.heatmap(calculateCovariance(replace_999_data_elem(tX),0), cmap=cmap, vmin=0)\n",
    "#plt.imshow(calculateCovariance(tX,1), cmap='Greys',  interpolation='nearest')\n",
    "\n",
    "ax1 = plt.subplot(2, 2, 2)\n",
    "plt.title(\"Correlation matrix with black box when values exceed 90%\")\n",
    "# data can include the colors\n",
    "plt.imshow(calculateCovariance(replace_999_data_elem(tX),True), cmap='Greys',  interpolation='nearest')\n",
    "\n",
    "# Remove the top and right axes from the data plot\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "\n",
    "#creation of segmentation train and train_test 90% / 10%\n",
    "y_train,y_train_test,tx_train,tx_train_test=split_data_train_test(y,tX_1,0.90)\n",
    "\n",
    "#calculate of the weights with the train part \n",
    "#tx_train_poly=build_poly(tx_train,5)\n",
    "tX_train_poly=build_poly_variance(tx_train,0,8,8,8,8,8)\n",
    "\n",
    "features_poly=get_uncorrelated_features(tX_train_poly)\n",
    "#print(\"shape tX_train_poly :\",np.shape(tX_train_poly))\n",
    "#tX_train_poly=tX_train_poly[:,features_poly]\n",
    "#print(\"shape tX_train_poly after :\",np.shape(tX_train_poly))\n",
    "\n",
    "\n",
    "weights, loss = ridge_regression(y_train, tX_train_poly, lambda_)\n",
    "#tX_train_test_poly=build_poly(tx_train_test,5)\n",
    "tX_train_test_poly=build_poly_variance(tx_train_test,0,8,8,8,8,8)\n",
    "#tX_train_test_poly=tX_train_test_poly[:,features_poly]\n",
    "print(\"train test :\", np.shape(tX_train_test_poly))\n",
    "print(\"Test: Loss = \", compute_loss(y_train_test, tX_train_test_poly, weights))\n",
    "print(\"Test: Real  accuracy = \", compute_loss_binary(y_train_test,tX_train_test_poly,weights))\n",
    "\n",
    "\n",
    "tX_test_poly = build_poly_variance(tX_test,0,8,8,8,8,8)\n",
    "#0.28631\n",
    "#0.2853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/result.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test_poly)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_find_degree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-e5301ec541e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_find_degree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtx_train_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n best_array = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_find_degree' is not defined"
     ]
    }
   ],
   "source": [
    "loss,best_array=test_find_degree(y_train,y_train_test,tx_train,tx_train_test)\n",
    "print(\"Loss = \", loss, \"\\n best_array = \", best_array)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  7  8  9 10 11 13 14 15 16 17 18 19 20 22 23]\n",
      "20\n",
      "y shape (250000,)\n",
      "tX shape (250000, 30)\n",
      "(array([0]),)\n"
     ]
    }
   ],
   "source": [
    "features=get_uncorrelated_features(tX)\n",
    "#print(features)\n",
    "#print(len(features[0]))\n",
    "print(features)\n",
    "print(len(features))\n",
    "print(\"y shape\", np.shape(y))\n",
    "print(\"tX shape\", np.shape(tX))\n",
    "print(calculateCovariance_y_tX(tX,y))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  7  8  9 10 11 13 14 15 16 17 18 19 20 22 23]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (225000,) (225000,21) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-31c0311d3e93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogistic_regression_S\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX_train_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"real loss: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcompute_loss_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtX_train_test_poly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MachineLearning/ML/scripts/implementations.py\u001b[0m in \u001b[0;36mlogistic_regression_S\u001b[0;34m(y, tx, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MachineLearning/ML/scripts/implementations.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;34m\"\"\"Calculate the loss using mean squared error (MSE)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (225000,) (225000,21) "
     ]
    }
   ],
   "source": [
    "lambda_=0.0\n",
    "tX_1=replace_999_data_elem(standardize(tX))\n",
    "features=get_uncorrelated_features(tX_1)\n",
    "tX_test=replace_999_data_elem(tX_test1)\n",
    "print(features)\n",
    "#### on prend que les features importants pas ceux qui sont correlés à plus de 90% avec les autres\n",
    "tX_1=tX_1[:,features]\n",
    "\n",
    "tX_test=tX_test1[:,features]\n",
    "y_train,y_train_test,tx_train,tx_train_test=split_data_train_test(y,tX_1,0.90)\n",
    "\n",
    "tX_train_poly=build_poly_variance(tx_train,0,1,1,1,1,1)\n",
    "tX_train_test_poly=build_poly_variance(tx_train_test,0,1,1,1,1,1)\n",
    "#Define initial values \n",
    "initial_w=np.zeros(np.shape(tX_train_poly)[1])\n",
    "#on change ici parce qu'on applique comme dans le cours avec des 0 ou des -1.\n",
    "y_train=np.where(y_train==-1,0,1)\n",
    "\n",
    "max_iters=100\n",
    "gamma=1e-9\n",
    "weights,loss=logistic_regression_S(y_train, tX_train_poly, initial_w, max_iters, gamma)\n",
    "print(\"loss\",loss)\n",
    "print(\"real loss: \",compute_loss_binary(y_train_test,tX_train_test_poly,weights))\n",
    "#print(\"train test :\", np.shape(tX_train_test_poly))\n",
    "#print(\"Test: Loss = \", compute_loss(y_train_test, tX_train_test_poly, weiughts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_train_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-21c4cce852b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MachineLearning/ML/scripts/implementations.py\u001b[0m in \u001b[0;36mtest_fct\u001b[0;34m(tX, y, lambda_, i)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0mtX_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtX_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;31m# creation of segmentation train and train_test 90% / 10%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx_train_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m     \u001b[0;31m# calculate of the weights with the train part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# tx_train_poly=build_poly(tx_train,5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_train_test' is not defined"
     ]
    }
   ],
   "source": [
    "lambdas=np.zeros(20)\n",
    "results=np.zeros((10,20))\n",
    "lambdas[1]=1e-6\n",
    "for i in range(2,20):\n",
    "    lambdas[i]=lambdas[i-1]*10\n",
    "for j in range(11):\n",
    "    for i in range(20):\n",
    "        results[j,i]=test_fct(tX,y,lambdas[i],j)\n",
    "\n",
    "plt.imshow(results)\n",
    "print(\"our maximum accuracy is : \" ,np.max(results))\n",
    "indexs=zip(*np.where(results == np.max(results)))\n",
    "print(\"The value of lambdas = \", lambdas[indexs[1]], \" and the value of j :\" , indexs[0])\n",
    "#plt.plot(lambdas,results)\n",
    "#plt.scatter(lambdas,results)\n",
    "#plt.xscale(\"log\")\n",
    "#plt.xlabel(\"lambdas\")\n",
    "#plt.ylabel(\"accuracy\")\n",
    "#plt.title(\"lambdas value and accuracy\")\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
